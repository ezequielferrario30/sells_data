# ğŸ“ Proyecto Integrador de Data Engineering â€“ README

---

## 1. Â¿QuÃ© se hizo?

Se diseÃ±Ã³ e implementÃ³ un sistema completo de anÃ¡lisis de ventas para una empresa de comestibles con mÃºltiples sucursales, simulando un entorno real de ingenierÃ­a de datos.  
El sistema abarca desde la carga de datos desde archivos CSV a una base de datos MySQL, el modelado orientado a objetos en Python, la aplicaciÃ³n de patrones de diseÃ±o (Factory, Singleton), la construcciÃ³n de objetos SQL avanzados (funciÃ³n, trigger, procedimiento almacenado, vista, Ã­ndice), la ejecuciÃ³n de consultas SQL avanzadas (CTEs y funciones de ventana), la integraciÃ³n total desde Python, la visualizaciÃ³n analÃ­tica, y la validaciÃ³n con testing automatizado y cobertura profesional.

---

## 2. Â¿CÃ³mo estÃ¡ organizado el proyecto?

```
ventas_data_engineering/
â”œâ”€â”€ venv/                   # Entorno virtual (EXCLUIDO del repositorio)
â”œâ”€â”€ data/                   # CSVs originales (input)
â”‚   â”œâ”€â”€ categories.csv
â”‚   â”œâ”€â”€ cities.csv
â”‚   â”œâ”€â”€ countries.csv
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ employees.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â””â”€â”€ sales.csv
â”‚
â”œâ”€â”€ src/                    # CÃ³digo fuente principal del proyecto
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ database_sqlalchemy.py
â”‚   â”œâ”€â”€ load_data.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ category.py
â”‚       â”œâ”€â”€ city.py
â”‚       â”œâ”€â”€ country.py
â”‚       â”œâ”€â”€ customer.py
â”‚       â”œâ”€â”€ employee.py
â”‚       â”œâ”€â”€ product.py
â”‚       â”œâ”€â”€ sale.py
â”‚       â””â”€â”€ factory.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ load_data.sql
â”‚   â”œâ”€â”€ create_functions.sql
â”‚   â”œâ”€â”€ create_views.sql
â”‚   â”œâ”€â”€ create_procedures.sql
â”‚   â”œâ”€â”€ create_triggers.sql
â”‚   â”œâ”€â”€ create_indexes.sql
â”‚   â””â”€â”€ analysis_queries.sql
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_customer.py
â”‚   â”œâ”€â”€ test_product.py
â”‚   â”œâ”€â”€ test_sale.py
â”‚   â”œâ”€â”€ test_factory.py
â”‚   â”œâ”€â”€ test_database_sqlalchemy.py
â”‚   â”œâ”€â”€ test_integracion_objetos_sql.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ integracion_final.ipynb         # Notebook de integraciÃ³n Avance 1 (base, modelos, queries, patrones, tests)
â”œâ”€â”€ integracion_objetos_sql.ipynb   # Notebook de integraciÃ³n Avance 2 (objetos SQL, ejecuciÃ³n, visualizaciones)
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```



---

## 3. JustificaciÃ³n tÃ©cnica y decisiones clave

### Carga de datos automatizada

- **Script**: `load_data.sql` con `LOAD DATA LOCAL INFILE` para importar eficientemente los CSV.
- **Ventajas**: Recarga grandes volÃºmenes, reproducible, portable y trazable. Evita errores manuales.
- **DecisiÃ³n**: Es preferible a carga manual, minimiza errores y maximiza performance y auditabilidad.

### Modelado orientado a objetos (POO)

- **Clases**: Cada entidad de negocio (producto, cliente, venta, etc.) es una clase Python con encapsulamiento, constructores y mÃ©todos de negocio.
- **Ventajas**: Centraliza reglas, facilita validaciones y cambios futuros del modelo.
- **DecisiÃ³n**: Refleja prÃ¡cticas reales de desarrollo profesional y escalable.

### Patrones de diseÃ±o: comparaciÃ³n y justificaciÃ³n

| PatrÃ³n         | UbicaciÃ³n / AplicaciÃ³n                 | Â¿Para quÃ© se usa?                                        | Ventajas principales                                                                      | Â¿Por quÃ© se eligiÃ³ sobre otros?                          |
| -------------- | -------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------------------------------------------- | -------------------------------------------------------- |
| Factory Method | src/models/factory.py                  | Centralizar y estandarizar creaciÃ³n de entidades         | Modularidad, escalabilidad, mantenimiento, nuevas fuentes de datos fÃ¡ciles                | MÃ¡s simple/flexible que Abstract Factory o Builder        |
| Singleton      | src/database.py, src/database_sqlalchemy.py | Garantizar instancia Ãºnica de conexiÃ³n a la base de datos | Eficiencia, seguridad, evita fugas de recursos, punto de acceso Ãºnico                     | MÃ¡s simple/directo que Object Pool o Service Locator      |

**ReflexiÃ³n:**  
Se priorizÃ³ escalabilidad, mantenibilidad y claridad. Las alternativas fueron evaluadas y se eligiÃ³ lo Ã³ptimo para la escala y el dominio, siempre alineado a buenas prÃ¡cticas.

---

### Objetos SQL y consultas avanzadas

- **FunciÃ³n**: `calcular_descuento` centraliza la lÃ³gica de descuentos por tipo de cliente.
- **Vista**: `ventas_mensuales_ciudad_categoria` para reportes segmentados y dashboards rÃ¡pidos.
- **Procedimiento almacenado**: `registrar_venta` estandariza la carga de ventas, permite validar y auditar.
- **Trigger**: registra logs de ventas en tiempo real y aplica reglas automÃ¡ticas, asegurando trazabilidad.
- **Ãndice**: mejora la performance en consultas frecuentes sobre ventas.
- **Consultas avanzadas**: uso intensivo de CTEs y funciones de ventana (`RANK`, `ROW_NUMBER`, `DENSE_RANK`, `SUM() OVER`), mostrando dominio de SQL avanzado y analÃ­tica real.

**DecisiÃ³n**:  
El diseÃ±o de estos objetos responde a necesidades analÃ­ticas y de negocio reales, y demuestra cÃ³mo el modelo puede evolucionar con nuevas reglas.

---

### IntegraciÃ³n total desde Python

- Todo el pipeline (creaciÃ³n y consulta de objetos SQL, ejecuciÃ³n de funciones/procedimientos, visualizaciones, logs) se realiza desde Python usando SQLAlchemy y pandas.
- Demuestra automatizaciÃ³n, reproducibilidad, y capacidad para construir pipelines robustos en ingenierÃ­a de datos.

---

### Visualizaciones analÃ­ticas

- Incluye grÃ¡ficos de:  
    - EvoluciÃ³n de ventas mensuales  
    - Top productos y clientes  
    - DistribuciÃ³n por ciudad y tipo de cliente  
    - EvoluciÃ³n por categorÃ­a  
- Las visualizaciones apoyan la interpretaciÃ³n de los resultados y la toma de decisiones estratÃ©gicas.

---

### Testing y calidad

- Tests unitarios y de integraciÃ³n con `pytest`:
    - Validan modelos, lÃ³gica de negocio, patrones y objetos SQL.
    - Chequean que los triggers y funciones trabajan en conjunto y que la integraciÃ³n Python-SQL es correcta.
- Asegura robustez, calidad, y fÃ¡cil refactorizaciÃ³n.

---

### Seguridad y buenas prÃ¡cticas

- Credenciales sÃ³lo en `.env` (no versionado).
- CÃ³digo seguro, portable y fÃ¡cil de configurar.
- `.gitignore` bien configurado, sin datos sensibles ni entorno virtual.

---

### OrganizaciÃ³n y reproducibilidad

- Proyecto ordenado por responsabilidad, versiÃ³n controlada y documentada.
- Notebooks integradores (`integracion_final.ipynb`, `integracion_objetos_sql.ipynb`) muestran outputs, explicaciones y justificaciones, cumpliendo con los criterios de evaluaciÃ³n y prÃ¡cticas profesionales.

---

## 4. Â¿CÃ³mo ejecutar el proyecto?

**1. Clonar el repositorio y crear un entorno virtual:**
```bash
git clone [URL_DEL_REPO]
cd ventas_data_engineering
python -m venv venv
source venv/bin/activate  # O .\venv\Scripts\activate en Windows
pip install -r requirements.txt
```

2. Configurar el archivo .env con credenciales de la base.

3. Ejecutar el script SQL de carga:

Desde MySQL Workbench: abrir y ejecutar sql/load_data.sql y los demÃ¡s scripts de sql/ para crear funciones, triggers, vistas, Ã­ndices y procedimientos.

4. Correr los tests:

```

pytest


```

5. Ejecutar los notebooks:

integracion_final.ipynb (avance 1, integraciÃ³n base y modelos)

integracion_objetos_sql.ipynb (avance 2, objetos SQL, ejecuciones, outputs y visualizaciones)

6. Explorar o ejecutar scripts adicionales desde src/.

----- 

# 5. Repositorio y versionado

- Todo el cÃ³digo, SQL, tests, notebooks y documentaciÃ³n estÃ¡n versionados y justificados.

- No se suben datos sensibles ni entorno virtual, cumpliendo estÃ¡ndares de seguridad y profesionalismo.

- Cada cambio estÃ¡ registrado para trazabilidad y auditorÃ­a.

---

## Lecciones aprendidas

- La importancia de la **modularidad y el versionado**: Organizar el cÃ³digo y los SQL en carpetas bien definidas acelera el desarrollo y el debugging.
- **Automatizar la carga y modelado** desde el inicio reduce errores y permite iterar mÃ¡s rÃ¡pido sobre los datos.
- La **integraciÃ³n entre Python y SQL** permite construir pipelines reproducibles y profesionales, facilitando el anÃ¡lisis y la visualizaciÃ³n de los resultados.
- El uso de **patrones de diseÃ±o** no es solo teÃ³rico: hacen el sistema mucho mÃ¡s mantenible, especialmente cuando los requerimientos cambian.
- Los **tests de integraciÃ³n** ayudan a detectar rÃ¡pidamente cualquier ruptura en la lÃ³gica entre objetos SQL y cÃ³digo Python, ahorrando tiempo en debugging.
- Documentar **decisiones y supuestos** en README y notebooks hace que el trabajo sea entendible y defendible ante cualquier auditorÃ­a.



---

## FAQ / Troubleshooting

**Â¿QuÃ© hago si el script SQL da error de permisos o ruta?**  
Verifica que el usuario de MySQL tenga permisos de `FILE`, y que la ruta de los CSV sea correcta para el sistema operativo.

**Â¿Por quÃ© me sale â€œAccess denied for userâ€ al correr desde Python?**  
Chequea que las credenciales y el nombre de la base estÃ©n bien configurados en `.env` y que ese usuario tenga permisos suficientes.

**Â¿CÃ³mo sÃ© si los triggers y funciones estÃ¡n activos?**  
Puedes consultar `SHOW TRIGGERS;` y `SHOW FUNCTION STATUS WHERE Db = 'ventas';` en MySQL Workbench.  
AdemÃ¡s, el notebook muestra los logs generados por triggers.

**Â¿Puedo cambiar o ampliar el modelo de datos?**  
SÃ­. Si agregas una nueva lÃ³gica de negocio (por ejemplo, tipos de productos), puedes agregar columnas y adaptar los modelos y scripts siguiendo el mismo enfoque modular.

**Â¿CÃ³mo veo los outputs si corro los notebooks en otro entorno?**  
AsegÃºrate de ejecutar cada celda. Si el entorno no tiene las librerÃ­as, instala con `pip install -r requirements.txt` y verifica la conexiÃ³n a la base.




---

# 6. ReflexiÃ³n final

Cada decisiÃ³n de diseÃ±o se fundamentÃ³ en maximizar mantenibilidad, eficiencia, escalabilidad y claridad, usando patrones y tÃ©cnicas seleccionadas por sus ventajas reales y justificadas en cada punto.
La soluciÃ³n refleja tanto la aplicaciÃ³n del conocimiento tÃ©cnico como la capacidad de razonar y justificar decisiones, habilidades clave para un ingeniero de datos profesional.

El resultado es un sistema reproducible, robusto, seguro y defendible, alineado con las mejores prÃ¡cticas del sector y las expectativas del negocio.